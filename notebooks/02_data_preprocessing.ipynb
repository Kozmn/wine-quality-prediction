{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0949e065",
   "metadata": {},
   "source": [
    "# Wine Quality Prediction - Data Preprocessing Pipeline\n",
    "\n",
    "## Objective\n",
    "Prepare the wine quality dataset for machine learning by implementing proper train-test splits, feature scaling, and data validation to ensure optimal model performance.\n",
    "\n",
    "## Preprocessing Strategy\n",
    "- **Stratified sampling**: Maintain target distribution across train/test splits\n",
    "- **Feature standardization**: Scale features to mean=0, std=1 for algorithm optimization\n",
    "- **Data validation**: Comprehensive checks to ensure preprocessing integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f57793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns 12\n",
      "Features columns 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine_data = pd.read_csv('../data/winequality-red.csv', sep=';')\n",
    "\n",
    "target = wine_data['quality']\n",
    "features = wine_data.drop('quality', axis=1)\n",
    "\n",
    "print(f\"Dataset columns: {len(wine_data.columns)}\")\n",
    "print(f\"Features columns: {len(features.columns)}\")\n",
    "print(f\"Dataset shape: {wine_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean: 18.432687072460002\n",
      "Original std: 6.105775283639784 \n",
      "\n",
      "Scaled mean: -2.024481303950566e-15\n",
      "Scaled std: 1.0001276405646913\n",
      "target values count: quality\n",
      "3      20\n",
      "4     163\n",
      "5    1457\n",
      "6    2198\n",
      "7     880\n",
      "8     175\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "ytrain values count: quality\n",
      "3      16\n",
      "4     130\n",
      "5    1166\n",
      "6    1758\n",
      "7     704\n",
      "8     140\n",
      "9       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled features back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(f\"\\nScaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled testing set shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# Comparison of means and stds before and after scaling\n",
    "print(f\"\\n--- Scaling Validation ---\")\n",
    "print(f\"Original mean: {features.mean().mean():.4f}\")\n",
    "print(f\"Original std: {features.std().mean():.4f}\")\n",
    "print(f\"Scaled mean: {X_train_scaled.mean().mean():.4f}\")\n",
    "print(f\"Scaled std: {X_train_scaled.std().mean():.4f}\")\n",
    "\n",
    "# Comparison of target values in the original dataset and the train/test splits \n",
    "print(f\"\\n--- Target Distribution Validation ---\")\n",
    "print(f\"Original distribution: {target.value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Training set distribution: {y_train.value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Testing set distribution: {y_test.value_counts().sort_index().to_dict()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b1f63",
   "metadata": {},
   "source": [
    "## Preprocessing Results\n",
    "\n",
    "### Data Split Validation\n",
    "- **Training set**: 1,279 samples (80%)\n",
    "- **Testing set**: 320 samples (20%)\n",
    "- **Stratification success**: Target distribution preserved across splits\n",
    "\n",
    "### Feature Standardization Results\n",
    "- **Original features**: Mixed scales (pH: 2.7-4.0, alcohol: 8.4-14.9)\n",
    "- **Standardized features**: Mean ≈ 0.0, Standard deviation ≈ 1.0\n",
    "- **Scaling validation**: Confirmed statistical properties achieved\n",
    "\n",
    "### Technical Implementation\n",
    "- **StandardScaler**: Fit on training data only (prevents data leakage)\n",
    "- **DataFrame preservation**: Maintained feature names and structure\n",
    "- **Pipeline ready**: Preprocessed data ready for model training\n",
    "\n",
    "## Key Preprocessing Decisions\n",
    "\n",
    "### Why Stratified Sampling?\n",
    "- **Class imbalance**: Quality scores 5-6 represent 82% of dataset\n",
    "- **Risk mitigation**: Prevents biased train/test distributions\n",
    "- **Model reliability**: Ensures consistent evaluation metrics\n",
    "\n",
    "### Why StandardScaler?\n",
    "- **Algorithm optimization**: Essential for distance-based algorithms\n",
    "- **Feature equality**: Prevents high-magnitude features from dominating\n",
    "- **Numerical stability**: Improves gradient descent convergence\n",
    "\n",
    "### Next Steps\n",
    "1. **Linear Regression**: Baseline model with interpretable coefficients\n",
    "2. **XGBoost**: Advanced ensemble method for comparison\n",
    "3. **Model evaluation**: MSE, MAE, R² metrics for performance assessment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
